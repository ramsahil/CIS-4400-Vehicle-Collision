{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0b8bdd4e700647ba2b08c59e5df8b7da1dcf50a218bcd4c1bcd9b3dc92e8788e5",
   "display_name": "Python 3.9.4 64-bit ('3.9')"
  },
  "metadata": {
   "interpreter": {
    "hash": "b8bdd4e700647ba2b08c59e5df8b7da1dcf50a218bcd4c1bcd9b3dc92e8788e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Requirements\n",
    "- install python3.9\n",
    "- install mysql server on Mac via homebrew `brew install mysql` (use chocolatey instead of brew for windows)\n",
    "- start the mysql server `brew services start mysql`\n",
    "- install the mysql python client `pip3 install sqlalchemy`\n",
    "- run this notebook (e.g.: VSCode's jupyter extension)\n",
    "\n",
    "# Links\n",
    "- installing python3.9: https://www.python.org/downloads/\n",
    "- installing homebrew: https://brew.sh/\n",
    "- installing VSCode and the jupyter extension: https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import sqlalchemy #pymyql isnt supported by pandas.to_sql"
   ]
  },
  {
   "source": [
    "# Extraction of Data from API's and CSV's"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACTION\n",
    "\n",
    "collision_data = pd.read_csv(\"https://data.cityofnewyork.us/resource/h9gi-nx95.csv\")\n",
    "features = [\"collision_id\", \"crash_time\", \"borough\", \"zip_code\", \"contributing_factor_vehicle_1\", \"contributing_factor_vehicle_2\", \"number_of_persons_injured\", \"number_of_persons_killed\",\"crash_date\"]\n",
    "collision_data = collision_data.loc[:,features]\n",
    "collision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = pd.read_csv(\"uber_nyc_enriched.csv\")  \n",
    "features = [\"pickups\", \"spd\", \"vsb\", \"temp\", \"pcp01\", \"pcp06\", \"pcp24\", \"sd\", \"borough\", \"hday\", \"pickup_dt\"]\n",
    "uber_data = uber_data.loc[:,features]\n",
    "\n",
    "uber_data.insert(0, \"uber_id\", [i for i in range(len(uber_data))])\n",
    "uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_incident_data = pd.read_csv(\"party_in_nyc.csv\")  \n",
    "features = [\"Created Date\", \"Incident Zip\", \"Borough\", \"Location Type\"]\n",
    "noise_incident_data = noise_incident_data.loc[:,features]\n",
    "\n",
    "noise_incident_data.insert(0, \"incident_id\", [i for i in range(len(noise_incident_data))])\n",
    "noise_incident_data"
   ]
  },
  {
   "source": [
    "# Transformation of Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NaN\n",
    "collision_data.dropna(inplace=True)\n",
    "\n",
    "#Concatenate crash_time and crash_date into one column, convert to proper SQL date-time format, and drop the crash_time column\n",
    "\n",
    "collision_data['crash_date'] = collision_data['crash_date'].str[:10]\n",
    "collision_data['crash_date'] = collision_data['crash_date'] + ' ' +  collision_data['crash_time']\n",
    "collision_data['crash_date'] = pd.to_datetime(collision_data['crash_date'], format='%Y-%m-%d %H:%M')\n",
    "del collision_data['crash_time']\n",
    "\n",
    "#change data types\n",
    "collision_data.dtypes\n",
    "collision_data['collision_id'] = collision_data['collision_id'].astype(int)\n",
    "collision_data['borough'] = collision_data['borough'].astype(str)\n",
    "collision_data['zip_code'] = collision_data['zip_code'].astype(int)\n",
    "collision_data['contributing_factor_vehicle_1'] = collision_data['contributing_factor_vehicle_1'].astype(str)\n",
    "collision_data['contributing_factor_vehicle_2'] = collision_data['contributing_factor_vehicle_2'].astype(str)\n",
    "collision_data['number_of_persons_injured'] = collision_data['number_of_persons_injured'].astype(int)\n",
    "collision_data['number_of_persons_killed'] = collision_data['number_of_persons_killed'].astype(int)\n",
    "\n",
    "collision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary value in borough\n",
    "noise_incident_data.Borough.unique()\n",
    "noise_incident_data = noise_incident_data[noise_incident_data.Borough != 'Unspecified']\n",
    "\n",
    "#change data types\n",
    "noise_incident_data.dtypes\n",
    "noise_incident_data['incident_id'] = noise_incident_data['incident_id'].astype(int)\n",
    "noise_incident_data['Incident Zip'] = noise_incident_data['Incident Zip'].astype(float)\n",
    "noise_incident_data['Borough'] = noise_incident_data['Borough'].astype(str)\n",
    "noise_incident_data['Location Type'] = noise_incident_data['Location Type'].astype(str)\n",
    "noise_incident_data['Created Date'] = pd.to_datetime(noise_incident_data['Created Date'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_incident_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to date time\n",
    "uber_data['pickup_dt'] = pd.to_datetime(uber_data['pickup_dt'], format = '%m/%d/%y %H:%M') #1/1/15 1:00\n",
    "\n",
    "#remove NaN values\n",
    "uber_data.dropna(inplace=True)\n",
    "\n",
    "#remove unnecessary boroughs\n",
    "uber_data.borough.unique()\n",
    "uber_data = uber_data[uber_data.borough != 'EWR']\n",
    "\n",
    "#match borough text with other dataframes\n",
    "uber_data['borough'] = uber_data['borough'].str.upper()\n",
    "\n",
    "#change data types\n",
    "uber_data.dtypes\n",
    "uber_data['uber_id'] = uber_data['uber_id'].astype(int)\n",
    "uber_data['pickups'] = uber_data['pickups'].astype(int)\n",
    "uber_data['borough'] = uber_data['borough'].astype(str)\n",
    "uber_data['hday'] = uber_data['hday'].astype(str)\n",
    "uber_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data"
   ]
  },
  {
   "source": [
    "## Creating dataframes with Pandas before loading data with sqlalchemy "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create Date Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.concat([\n",
    "    uber_data['pickup_dt'],\n",
    "    collision_data['crash_date'],\n",
    "    noise_incident_data['Created Date']\n",
    "], axis='columns')\n",
    "\n",
    "from datetime import datetime\n",
    "date= date.fillna(datetime(1900,1,1))\n",
    "date.insert(0, \"date_id\", [i for i in range(len(date))])\n",
    "date['date_id'] = date['date_id'].astype(int)\n",
    "date"
   ]
  },
  {
   "source": [
    "### Create Facts Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table_size = min(\n",
    "    len(collision_data),\n",
    "    len(uber_data),\n",
    "    len(noise_incident_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = pd.concat([uber_data,collision_data,noise_incident_data, date], axis='columns')[[\n",
    "    'uber_id',\n",
    "    'collision_id',\n",
    "    'incident_id',\n",
    "    'date_id',\n",
    "    'number_of_persons_injured',\n",
    "    'number_of_persons_killed',\n",
    "    'pickups',\n",
    "    'spd',\n",
    "    'vsb',\n",
    "    'temp',\n",
    "    'pcp01',\n",
    "    'pcp06',\n",
    "    'pcp24',\n",
    "    'sd'\n",
    "]]\n",
    "# facts['uber_id'] = facts['uber_id'].astype(int)\n",
    "# facts['collision_id'] = facts['collision_id'].astype(int)\n",
    "# facts['incident_id'] = facts['incident_id'].astype(int)\n",
    "# facts['date_id'] = facts['date_id'].astype(int)\n",
    "facts"
   ]
  },
  {
   "source": [
    "### Create Noise Incident Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_incident_data = noise_incident_data[[\n",
    "    'incident_id',\n",
    "    'Incident Zip', \n",
    "    'Borough', \n",
    "    'Location Type'\n",
    "]]    "
   ]
  },
  {
   "source": [
    "### Create Uber Data Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = uber_data[[\n",
    "    'uber_id', \n",
    "    'borough', \n",
    "    'hday'\n",
    "]]"
   ]
  },
  {
   "source": [
    "### Create Collision Data Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_data = collision_data[[\n",
    "    'collision_id',\n",
    "    'borough',\n",
    "    'zip_code',\n",
    "    'contributing_factor_vehicle_1',\n",
    "    'contributing_factor_vehicle_2'\n",
    "]]\n",
    "collision_data"
   ]
  },
  {
   "source": [
    "# Loading of Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Open Connection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a connection to mysql (because df.to_mysql does not take pymysql connections)\n",
    "client = sqlalchemy.create_engine('mysql+pymysql://root:@localhost:3306')\n",
    "\n",
    "#Create a database to run and store tables\n",
    "client.execute(\"DROP DATABASE IF EXISTS mydatabase\")\n",
    "client.execute(\"CREATE DATABASE mydatabase\")\n",
    "\n",
    "client = sqlalchemy.create_engine('mysql+pymysql://root:@localhost:3306/mydatabase')\n",
    "\n",
    "#execute a query to confirm first query worked\n",
    "results = client.execute(\"SHOW DATABASES\")\n",
    "for db in results: #Verify that mydatabase appears in the list when print statement is run\n",
    "\tprint(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idempotent\n",
    "df = uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(noise_incident_data)\n",
    "\n",
    "df.to_sql(\n",
    "    name = 'noise_incident_data',\n",
    "    con = client,\n",
    "    index = False,\n",
    "    if_exists = 'replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(uber_data)\n",
    "\n",
    "df.to_sql(\n",
    "    name = 'uber_data',\n",
    "    con = client,\n",
    "    index = False,\n",
    "    if_exists = 'replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(collision_data)\n",
    "\n",
    "df.to_sql(\n",
    "    name = 'collision_data',\n",
    "    con = client,\n",
    "    index = False,\n",
    "    if_exists = 'replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(facts)\n",
    "\n",
    "df.to_sql(\n",
    "    name = 'fact_dimension',\n",
    "    con = client,\n",
    "    index = False,\n",
    "    if_exists = 'replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(date)\n",
    "\n",
    "df.to_sql(\n",
    "    name = 'date_dimension',\n",
    "    con = client,\n",
    "    index = False,\n",
    "    if_exists = 'replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.execute(\"SELECT * FROM collision_data LIMIT 5\")\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.execute(\"SELECT * FROM date_dimension LIMIT 5\")\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.execute(\"SELECT * FROM noise_incident_data LIMIT 5\")\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.execute(\"SELECT * FROM uber_data LIMIT 5\")\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.execute(\"SELECT * FROM fact_dimension LIMIT 5\")\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  }
 ]
}